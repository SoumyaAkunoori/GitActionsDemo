trigger:
  branches:
    include:
    - dev
    #- main
    - azure-pipelines
  paths:
    include:
    - databricks/*

variables:
  subscription: '7b206cd2-248a-49a7-b5e0-6adf9df31cb2'
  resourceGroupName: 'Test-rg'
  databricksName: 'ADB-GIT-Demo'
#  PipelineName: '01_create_training_data'

pool:
  vmImage: ubuntu-latest

steps:

#- script: |
#    pip install pandas pytest pytest-azurepipelines
#    pip install pytest-cov
#    pytest tests/unittest/ --junitxml=junit/test-results.xml --cov=. --cov-report=xml --cov-report=html
#  displayName: 'Unit Test and Code Coverage'

- script: |
    pip install pylint
    pylint | find -name '*.py'
  displayName: 'Run lint tests'

#- task: SonarQubePrepare@5
#  inputs:
#    SonarQube: 'NLPPSonarQube'
#    scannerMode: 'CLI'
#    configMode: 'manual'
#    cliProjectKey: 'ODDA-Sonarqube'
#    cliProjectName: 'ODDA-Sonarqube'
#    cliSources: './data-bricks/'

#- task: SonarQubeAnalyze@5

#- task: SonarQubePublish@5
#  inputs:
#    pollingTimeoutSec: '300'

- task: PublishTestResults@2
  inputs:
    testResultsFiles: 'junit/*.xml'
  condition: succeededOrFailed()

# Copy notebooks to $(build.artifactstagingdirectory)
- task: CopyFiles@2
  inputs:
    SourceFolder: 'databricks'
    Contents: '**'
    TargetFolder: '$(build.artifactstagingdirectory)'

- task: PublishBuildArtifacts@1
  inputs:
    PathtoPublish: '$(Build.ArtifactStagingDirectory)'
    ArtifactName: 'drop-notebooks'
    publishLocation: 'Container'
